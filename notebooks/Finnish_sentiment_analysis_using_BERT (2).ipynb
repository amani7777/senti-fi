{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Finnish_sentiment_analysis_using_BERT",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PGnlRWvkY-2c"
      },
      "source": [
        "# Sentiment Analysis with BERT\n",
        "\n",
        "> TL;DR In this tutorial, you'll learn how to fine-tune BERT for sentiment analysis. You'll do the required text preprocessing (special tokens, padding, and attention masks) and build a Sentiment Classifier using the amazing Transformers library by Hugging Face!\n",
        "\n",
        "- [Read the tutorial](https://www.curiousily.com/posts/sentiment-analysis-with-bert-and-hugging-face-using-pytorch-and-python/)\n",
        "- [Run the notebook in your browser (Google Colab)](https://colab.research.google.com/drive/1PHv-IRLPCtv7oTcIGbsgZHqrB5LPvB7S)\n",
        "- [Read the `Getting Things Done with Pytorch` book](https://github.com/curiousily/Getting-Things-Done-with-Pytorch)\n",
        "\n",
        "You'll learn how to:\n",
        "\n",
        "- Intuitively understand what BERT is\n",
        "- Preprocess text data for BERT and build PyTorch Dataset (tokenization, attention masks, and padding)\n",
        "- Use Transfer Learning to build Sentiment Classifier using the Transformers library by Hugging Face\n",
        "- Evaluate the model on test data\n",
        "- Predict sentiment on raw text\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NJ6MhJYYBCwu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "b855412e-2c8f-4585-c5b7-fed5cd238e9a"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jul 22 19:57:01 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.51.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8    31W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Tbodro8Fpmwr"
      },
      "source": [
        "## What is BERT?\n",
        "\n",
        "BERT (introduced in [this paper](https://arxiv.org/abs/1810.04805)) stands for Bidirectional Encoder Representations from Transformers. If you don't know what most of that means - you've come to the right place! Let's unpack the main ideas:\n",
        "\n",
        "- Bidirectional - to understand the text  you're looking you'll have to look back (at the previous words) and forward (at the next words)\n",
        "- Transformers - The [Attention Is All You Need](https://arxiv.org/abs/1706.03762) paper presented the Transformer model. The Transformer reads entire sequences of tokens at once. In a sense, the model is non-directional, while LSTMs read sequentially (left-to-right or right-to-left). The attention mechanism allows for learning contextual relations between words (e.g. `his` in a sentence refers to Jim).\n",
        "- (Pre-trained) contextualized word embeddings - [The ELMO paper](https://arxiv.org/abs/1802.05365v2) introduced a way to encode words based on their meaning/context. Nails has multiple meanings - fingernails and metal nails.\n",
        "\n",
        "BERT was trained by masking 15% of the tokens with the goal to guess them. An additional objective was to predict the next sentence. Let's look at examples of these tasks:\n",
        "\n",
        "### Masked Language Modeling (Masked LM)\n",
        "\n",
        "The objective of this task is to guess the masked tokens. Let's look at an example, and try to not make it harder than it has to be:\n",
        "\n",
        "That's `[mask]` she `[mask]` -> That's what she said\n",
        "\n",
        "### Next Sentence Prediction (NSP)\n",
        "\n",
        "Given a pair of two sentences, the task is to say whether or not the second follows the first (binary classification). Let's continue with the example:\n",
        "\n",
        "*Input* = `[CLS]` That's `[mask]` she `[mask]`. [SEP] Hahaha, nice! [SEP]\n",
        "\n",
        "*Label* = *IsNext*\n",
        "\n",
        "*Input* = `[CLS]` That's `[mask]` she `[mask]`. [SEP] Dwight, you ignorant `[mask]`! [SEP]\n",
        "\n",
        "*Label* = *NotNext*\n",
        "\n",
        "The training corpus was comprised of two entries: [Toronto Book Corpus](https://arxiv.org/abs/1506.06724) (800M words) and English Wikipedia (2,500M words). While the original Transformer has an encoder (for reading the input) and a decoder (that makes the prediction), BERT uses only the decoder.\n",
        "\n",
        "BERT is simply a pre-trained stack of Transformer Encoders. How many Encoders? We have two versions - with 12 (BERT base) and 24 (BERT Large).\n",
        "\n",
        "### Is This Thing Useful in Practice?\n",
        "\n",
        "The BERT paper was released along with [the source code](https://github.com/google-research/bert) and pre-trained models.\n",
        "\n",
        "The best part is that you can do Transfer Learning (thanks to the ideas from OpenAI Transformer) with BERT for many NLP tasks - Classification, Question Answering, Entity Recognition, etc. You can train with small amounts of data and achieve great performance!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wmj22-TcZMef"
      },
      "source": [
        "## Setup\n",
        "\n",
        "We'll need [the Transformers library](https://huggingface.co/transformers/) by Hugging Face:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Kj_7Tz0-pK69",
        "colab": {}
      },
      "source": [
        "!pip install -q -U watermark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jjsbi1u3QFEM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "d746d0eb-2e98-46f1-bcd2-2f5aa0c02837"
      },
      "source": [
        "!pip install -qq transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 778kB 2.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 12.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.0MB 17.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 22.2MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AJqoaFpVpoM8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "d1e72fcc-c1b8-4dc7-919e-cbb56920067f"
      },
      "source": [
        "%reload_ext watermark\n",
        "%watermark -v -p numpy,pandas,torch,transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPython 3.6.9\n",
            "IPython 5.5.0\n",
            "\n",
            "numpy 1.18.5\n",
            "pandas 1.0.5\n",
            "torch 1.5.1+cu101\n",
            "transformers 3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "w68CZpOwFoly",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "edec75c0-ef14-46ef-cb98-9d20de46e9a6"
      },
      "source": [
        "#@title Setup & Config\n",
        "import transformers\n",
        "from transformers import BertModel,BertForMaskedLM, BertTokenizer, AdamW, get_linear_schedule_with_warmup, BertConfig\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "\n",
        "rcParams['figure.figsize'] = 12, 8\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ufzPdoTtNikq"
      },
      "source": [
        "## Data Exploration\n",
        "\n",
        "We'll load the Google Play app reviews dataset, that we've put together in the previous part:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yOeWFaUe_zK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "68b7d00a-de99-4311-dc61-cda2c55e7313"
      },
      "source": [
        "\n",
        "!gdown --id 1yGYZcIsFgTRd3aiMjIqWgH0KiHFxorAB\n",
        "!gdown --id 1G_6VW4QHl04ONB5xw3hp7GpfKIFLM4QM"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1yGYZcIsFgTRd3aiMjIqWgH0KiHFxorAB\n",
            "To: /content/finnish_reviews_cleaned.csv\n",
            "14.9MB [00:00, 24.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1G_6VW4QHl04ONB5xw3hp7GpfKIFLM4QM\n",
            "To: /content/bert-base-finnish-cased-v1.zip\n",
            "463MB [00:08, 53.2MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5D18AehXgqWp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "b0557a6e-ca07-46ed-a5fe-93a00db485fe"
      },
      "source": [
        "!unzip bert-base-finnish-cased-v1.zip\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  bert-base-finnish-cased-v1.zip\n",
            "   creating: bert-base-finnish-cased-v1/\n",
            "  inflating: bert-base-finnish-cased-v1/config.json  \n",
            "  inflating: bert-base-finnish-cased-v1/pytorch_model.bin  \n",
            "  inflating: bert-base-finnish-cased-v1/vocab.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mUKLyKc7I6Qp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d81c5438-2e98-45f8-f4e5-22187a9d36ea"
      },
      "source": [
        "df = pd.read_csv(\"finnish_reviews_cleaned.csv\")\n",
        "df.sentiment.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "positive    29100\n",
              "negative    29100\n",
              "neutral     24250\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgJDRxiOT3at",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dB2jE6am7Dpo",
        "colab": {}
      },
      "source": [
        "#df = df.sample(9000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TWqVNHJbn10l"
      },
      "source": [
        "We have about 16k examples. Let's check for missing values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VA_wGSLQLKCh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "3211c268-019a-4296-c5cc-c0ac0617d350"
      },
      "source": [
        "df.sample()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>appId</th>\n",
              "      <th>content</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>content_cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13577</th>\n",
              "      <td>110127</td>\n",
              "      <td>com.elisa.viihde</td>\n",
              "      <td>Tykkään sovelluksesta!</td>\n",
              "      <td>positive</td>\n",
              "      <td>tykkään sovelluksesta</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0             appId  ... sentiment         content_cleaned\n",
              "13577      110127  com.elisa.viihde  ...  positive  tykkään sovelluksesta \n",
              "\n",
              "[1 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "advkbnOwoSL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_int = {\n",
        "    'negative' : 0,\n",
        "    'neutral' : 1,\n",
        "    'positive':2\n",
        "}\n",
        "df['sentiment'] = df.sentiment.map(labels_int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "H3cL_1qVn_6h"
      },
      "source": [
        "Great, no missing values in the score and review texts! Do we have class imbalance?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXP0ZTUEoYcX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4abb73cc-1b02-40c6-cc35-63d3f6ef4c9e"
      },
      "source": [
        "df.sentiment.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    29100\n",
              "0    29100\n",
              "1    24250\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V-155O-SFSqE",
        "colab": {}
      },
      "source": [
        "class_names = ['negative', 'neutral', 'positive']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tOssB4CKnAX2"
      },
      "source": [
        "The balance was (mostly) restored."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9aHyGuTFgyPO"
      },
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "You might already know that Machine Learning models don't work with raw text. You need to convert text to numbers (of some sort). BERT requires even more attention (good one, right?). Here are the requirements: \n",
        "\n",
        "- Add special tokens to separate sentences and do classification\n",
        "- Pass sequences of constant length (introduce padding)\n",
        "- Create array of 0s (pad token) and 1s (real token) called *attention mask*\n",
        "\n",
        "The Transformers library provides (you've guessed it) a wide variety of Transformer models (including BERT). It works with TensorFlow and PyTorch! It also includes prebuild tokenizers that do the heavy lifting for us!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E7Mj-0ne--5t",
        "colab": {}
      },
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-finnish-cased-v1'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fMSr7C-F_sey"
      },
      "source": [
        "> You can use a cased and uncased version of BERT and tokenizer. I've experimented with both. The cased version works better. Intuitively, that makes sense, since \"BAD\" might convey more sentiment than \"bad\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NiLb-ltM-ZRz"
      },
      "source": [
        "Let's load a pre-trained [BertTokenizer](https://huggingface.co/transformers/model_doc/bert.html#berttokenizer):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H3AfJSZ8NNLF",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CfrSbwTQ-wi_"
      },
      "source": [
        "We'll use this text to understand the tokenization process:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HZMitwrqm2eb",
        "colab": {}
      },
      "source": [
        "sample_txt = 'Tykkään sovelluksesta!'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yO2qBTVl_KPs"
      },
      "source": [
        "Some basic operations can convert the text to tokens and tokens to unique integers (ids):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iTFhpHpsoWO7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e4657670-55f9-46de-de32-d34f249aa92c"
      },
      "source": [
        "tokens = tokenizer.tokenize(sample_txt)\n",
        "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "print(f' Sentence: {sample_txt}')\n",
        "print(f'   Tokens: {tokens}')\n",
        "print(f'Token IDs: {token_ids}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Sentence: Tykkään sovelluksesta!\n",
            "   Tokens: ['tyk', '##kaan', 'sovellu', '##ksesta', '!']\n",
            "Token IDs: [17111, 235, 33249, 9097, 380]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bzbbKLR8lZbu"
      },
      "source": [
        "### Special Tokens\n",
        "\n",
        "`[SEP]` - marker for ending of a sentence\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EXwz47bQvCbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3fd3ae8f-b72d-41dd-deb1-5e8bfb1fe1b7"
      },
      "source": [
        "tokenizer.sep_token, tokenizer.sep_token_id"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[SEP]', 103)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Mip_eGeXwLFF"
      },
      "source": [
        "`[CLS]` - we must add this token to the start of each sentence, so BERT knows we're doing classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_6K4it5HwE6l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a02b4dd6-913e-4b60-81cf-51752508e9a4"
      },
      "source": [
        "tokenizer.cls_token, tokenizer.cls_token_id"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[CLS]', 102)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Qi6O-yEY09gl"
      },
      "source": [
        "There is also a special token for padding:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Vx7gD5xf1AFK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e6589956-523a-4877-a2ee-ae0f33dbbc25"
      },
      "source": [
        "tokenizer.pad_token, tokenizer.pad_token_id"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[PAD]', 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6GWCfijM0TWB"
      },
      "source": [
        "BERT understands tokens that were in the training set. Everything else can be encoded using the `[UNK]` (unknown) token:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4cmfFsbEKQDT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "52c0e4cf-17f8-44d8-ee69-303ba87d712b"
      },
      "source": [
        "tokenizer.unk_token, tokenizer.unk_token_id"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[UNK]', 101)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "W9ap7jdL0LYU"
      },
      "source": [
        "All of that work can be done using the [`encode_plus()`](https://huggingface.co/transformers/main_classes/tokenizer.html#transformers.PreTrainedTokenizer.encode_plus) method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Vea9edaaxSPO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "8c70f1f6-d619-461a-8210-35e8ba66bcd2"
      },
      "source": [
        "encoding = tokenizer.encode_plus(\n",
        "  sample_txt,\n",
        "  max_length=32,\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "encoding.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sS69c8WvdOED"
      },
      "source": [
        "The token ids are now stored in a Tensor and padded to a length of 32:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YzBmcOla0yQR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "dee6f2f3-cdb3-4155-d1bd-01d9a4cf8e28"
      },
      "source": [
        "print(len(encoding['input_ids'][0]))\n",
        "encoding['input_ids'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  102, 17111,   235, 33249,  9097,   380,   103,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "itAyVPsNdyc1"
      },
      "source": [
        "The attention mask has the same length:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wiv5LLiw03Ox",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "00639bdf-fe10-4a52-ff27-3174ae69033b"
      },
      "source": [
        "print(len(encoding['attention_mask'][0]))\n",
        "encoding['attention_mask']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m1RvhC4jNHHy"
      },
      "source": [
        "We can inverse the tokenization to have a look at the special tokens:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IagGoafKLUwW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "cfc5a418-568c-42ce-c6ec-45399f31794d"
      },
      "source": [
        "tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'tyk',\n",
              " '##kaan',\n",
              " 'sovellu',\n",
              " '##ksesta',\n",
              " '!',\n",
              " '[SEP]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "waKjYxTDuaWt"
      },
      "source": [
        "### Choosing Sequence Length\n",
        "\n",
        "BERT works with fixed-length sequences. We'll use a simple strategy to choose the max length. Let's store the token length of each review:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xJMOPw9eNBS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJvQ60VC-4Fy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d30531e6-5ef7-4908-cc51-ab95dbaeb11c"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>appId</th>\n",
              "      <th>content</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>content_cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8259</td>\n",
              "      <td>com.yle.webtv</td>\n",
              "      <td>Luotettava sovellus ja Areenan huippusisällöt....</td>\n",
              "      <td>2</td>\n",
              "      <td>luotettava sovellus ja areenan huippusisällöt ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>104446</td>\n",
              "      <td>com.sevelina.frozenland</td>\n",
              "      <td>Kivoja mekkoja!</td>\n",
              "      <td>2</td>\n",
              "      <td>kivoja mekkoja</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>145434</td>\n",
              "      <td>com.swampsend.maastokartat</td>\n",
              "      <td>Saan kotimetsistäni hienot kartat. Tosi tarkat...</td>\n",
              "      <td>2</td>\n",
              "      <td>saan kotimetsistäni hienot kartat tosi tarkat ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>107060</td>\n",
              "      <td>air.fi.yle.pikkukakkonen</td>\n",
              "      <td>A versiost</td>\n",
              "      <td>2</td>\n",
              "      <td>a versiost</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>23565</td>\n",
              "      <td>com.nordea.mobiletoken</td>\n",
              "      <td>Tähän mennessä kätevin verkkopankkisovellus mi...</td>\n",
              "      <td>2</td>\n",
              "      <td>tähän mennessä kätevin verkkopankkisovellus mi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                    content_cleaned\n",
              "0        8259  ...  luotettava sovellus ja areenan huippusisällöt ...\n",
              "1      104446  ...                                    kivoja mekkoja \n",
              "2      145434  ...  saan kotimetsistäni hienot kartat tosi tarkat ...\n",
              "3      107060  ...                                         a versiost\n",
              "4       23565  ...  tähän mennessä kätevin verkkopankkisovellus mi...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63lkBs0Afyc_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "outputId": "6d124402-f2bd-4c33-fb9d-c14bd126959f"
      },
      "source": [
        "sns.distplot(df.content.apply(lambda x : len(str(x).split(' '))))\n",
        "plt.xlim([0, 256]);\n",
        "plt.xlabel('Token count');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 722,
              "height": 489
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oW6ajl30t6du"
      },
      "source": [
        "Most of the reviews seem to contain less than 128 tokens, but we'll be on the safe side and choose a maximum length of 160."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t7xSmJtLuoxW",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 75"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XvvcoU6nurHy"
      },
      "source": [
        "We have all building blocks required to create a PyTorch dataset. Let's do it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E2BPgRJ7YBK0",
        "colab": {}
      },
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "  \n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x2uwsvCYqDJK"
      },
      "source": [
        "The tokenizer is doing most of the heavy lifting for us. We also return the review texts, so it'll be easier to evaluate the predictions from our model. Let's split the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B-vWzoo81dvO",
        "colab": {}
      },
      "source": [
        "df_train, df_test = train_test_split(df, test_size=0.2, random_state=RANDOM_SEED)\n",
        "df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=RANDOM_SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xz3ZOQXVPCwh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4b04e4b9-5414-4510-9204-ebac3ba63099"
      },
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((65960, 5), (8245, 5), (8245, 5))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J4tQ1x-vqNab"
      },
      "source": [
        "We also need to create a couple of data loaders. Here's a helper function to do it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KEGqcvkuOuTX",
        "colab": {}
      },
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "    reviews=df.content_cleaned.to_numpy(),\n",
        "    targets=df.sentiment.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vODDxMKsPHqI",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "H63Y-TjyRC7S"
      },
      "source": [
        "## Sentiment Classification with BERT and Hugging Face"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "440Nd31VTHER"
      },
      "source": [
        "There are a lot of helpers that make using BERT easy with the Transformers library. Depending on the task you might want to use [BertForSequenceClassification](https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification), [BertForQuestionAnswering](https://huggingface.co/transformers/model_doc/bert.html#bertforquestionanswering) or something else. \n",
        "\n",
        "But who cares, right? We're *hardcore*! We'll use the basic [BertModel](https://huggingface.co/transformers/model_doc/bert.html#bertmodel) and build our sentiment classifier on top of it. Let's load the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjnRrQcdeNB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-finnish-cased-v1/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0P41FayISNRI",
        "colab": {}
      },
      "source": [
        "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aFE7YSbFdY4t"
      },
      "source": [
        "And try to use it on the encoding of our sample text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s1aoFxbQSn15",
        "colab": {}
      },
      "source": [
        "last_hidden_state, pooled_output = bert_model(\n",
        "  input_ids=encoding['input_ids'], \n",
        "  attention_mask=encoding['attention_mask']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mLLu8zmqbaHV"
      },
      "source": [
        "The `last_hidden_state` is a sequence of hidden states of the last layer of the model. Obtaining the `pooled_output` is done by applying the [BertPooler](https://github.com/huggingface/transformers/blob/edf0582c0be87b60f94f41c659ea779876efc7be/src/transformers/modeling_bert.py#L426) on `last_hidden_state`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mUJHXNpIbcci",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "91a3dff8-fdf2-4ea0-b6cb-8666c85a1e9a"
      },
      "source": [
        "last_hidden_state.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 32, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q4dAot4zbz8k"
      },
      "source": [
        "We have the hidden state for each of our 32 tokens (the length of our example sequence). But why 768? This is the number of hidden units in the feedforward-networks. We can verify that by checking the config:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nsxB7Qy7b5YN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c09e6ba4-8a3f-4d9e-ef6e-78ae7f826b76"
      },
      "source": [
        "bert_model.config.hidden_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wTKi8-rTd_j4"
      },
      "source": [
        "\n",
        "\n",
        "You can think of the `pooled_output` as a summary of the content, according to BERT. Albeit, you might try and do better. Let's look at the shape of the output:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2jIAtRhaSz9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "16f558f2-4c07-40c5-ab5f-ddb472702d10"
      },
      "source": [
        "pooled_output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0o_NiS3WgOFf"
      },
      "source": [
        "We can use all of this knowledge to create a classifier that uses the BERT model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m_mRflxPl32F",
        "colab": {}
      },
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(SentimentClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UJg8m3NQJahc"
      },
      "source": [
        "Our classifier delegates most of the heavy lifting to the BertModel. We use a dropout layer for some regularization and a fully-connected layer for our output. Note that we're returning the raw output of the last layer since that is required for the cross-entropy loss function in PyTorch to work.\n",
        "\n",
        "This should work like any other PyTorch model. Let's create an instance and move it to the GPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i0yQnuSFsjDp",
        "colab": {}
      },
      "source": [
        "model = SentimentClassifier(len(class_names))\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g9xikRdtRN1N"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "76g7FV85H-T8"
      },
      "source": [
        "To reproduce the training procedure from the BERT paper, we'll use the [AdamW](https://huggingface.co/transformers/main_classes/optimizer_schedules.html#adamw) optimizer provided by Hugging Face. It corrects weight decay, so it's similar to the original paper. We'll also use a linear scheduler with no warmup steps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5v-ArJ2fCCcU",
        "colab": {}
      },
      "source": [
        "EPOCHS = 4\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=3e-5, correct_bias=False, weight_decay=0.01)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A8522g7JIu5J"
      },
      "source": [
        "How do we come up with all hyperparameters? The BERT authors have some recommendations for fine-tuning:\n",
        "\n",
        "- Batch size: 16, 32\n",
        "- Learning rate (Adam): 5e-5, 3e-5, 2e-5\n",
        "- Number of epochs: 2, 3, 4\n",
        "\n",
        "We're going to ignore the number of epochs recommendation but stick with the rest. Note that increasing the batch size reduces the training time significantly, but gives you lower accuracy.\n",
        "\n",
        "Let's continue with writing a helper function for training our model for one epoch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bzl9UhuNx1_Q",
        "colab": {}
      },
      "source": [
        "def train_epoch(\n",
        "  model, \n",
        "  data_loader, \n",
        "  loss_fn, \n",
        "  optimizer, \n",
        "  device, \n",
        "  scheduler, \n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  \n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E4PniYIte0fr"
      },
      "source": [
        "Training the model should look familiar, except for two things. The scheduler gets called every time a batch is fed to the model. We're avoiding exploding gradients by clipping the gradients of the model using [clip_grad_norm_](https://pytorch.org/docs/stable/nn.html#clip-grad-norm).\n",
        "\n",
        "Let's write another one that helps us evaluate the model on a given data loader:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CXeRorVGIKre",
        "colab": {}
      },
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAKB0Zt2qLKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a_rdSDBHhhCh"
      },
      "source": [
        "Using those two, we can write our training loop. We'll also store the training history:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1zhHoFNsxufs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "d4b7cb9f-640f-4fba-ad3a-8b0439fac136"
      },
      "source": [
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,    \n",
        "    loss_fn, \n",
        "    optimizer, \n",
        "    device, \n",
        "    scheduler, \n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn, \n",
        "    device, \n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "  if val_acc > best_accuracy:\n",
        "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "    best_accuracy = val_acc\n",
        "\n",
        "  if EPOCHS >= 15 and train_acc > 0.90:\n",
        "    files.download(\"best_model_state.bin\")\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "----------\n",
            "Train loss 0.90918303488471 accuracy 0.5608853850818678\n",
            "Val   loss 0.798414313978003 accuracy 0.6168587022437841\n",
            "\n",
            "Epoch 2/4\n",
            "----------\n",
            "Train loss 0.7521250557974631 accuracy 0.6491206791995149\n",
            "Val   loss 0.7494645769050879 accuracy 0.6587022437841116\n",
            "\n",
            "Epoch 3/4\n",
            "----------\n",
            "Train loss 0.6852794842276032 accuracy 0.693844754396604\n",
            "Val   loss 0.7383100157098252 accuracy 0.6725288053365677\n",
            "\n",
            "Epoch 4/4\n",
            "----------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4r8-5zWsiVur"
      },
      "source": [
        "Note that we're storing the state of the best model, indicated by the highest validation accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wLQf52c7fbzr"
      },
      "source": [
        "Whoo, this took some time! We can look at the training vs validation accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-FWG7kBm372V",
        "colab": {}
      },
      "source": [
        "plt.plot(history['train_acc'], label='train accuracy')\n",
        "plt.plot(history['val_acc'], label='validation accuracy')\n",
        "\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZsHqkLAuf8pv"
      },
      "source": [
        "The training accuracy starts to approach 100% after 10 epochs or so. You might try to fine-tune the parameters a bit more, but this will be good enough for us.\n",
        "\n",
        "Don't want to wait? Uncomment the next cell to download my pre-trained model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zoGUH8VZ-pPQ",
        "colab": {}
      },
      "source": [
        "# !gdown --id 1V8itWtowCYnb2Bc9KlK9SxGff9WwmogA\n",
        "\n",
        "# model = SentimentClassifier(len(class_names))\n",
        "# model.load_state_dict(torch.load('best_model_state.bin'))\n",
        "# model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U3HZb3NWFtFf"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "So how good is our model on predicting sentiment? Let's start by calculating the accuracy on the test data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jS3gJ_qBEljD",
        "colab": {}
      },
      "source": [
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "\n",
        "test_acc.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mdQ7-ylCj8Gd"
      },
      "source": [
        "The accuracy is about 1% lower on the test set. Our model seems to generalize well.\n",
        "\n",
        "We'll define a helper function to get the predictions from our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EgR6MuNS8jr_",
        "colab": {}
      },
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "  \n",
        "  review_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      texts = d[\"review_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "      review_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return review_texts, predictions, prediction_probs, real_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dkbnBTI7kd_y"
      },
      "source": [
        "This is similar to the evaluation function, except that we're storing the text of the reviews and the predicted probabilities (by applying the softmax on the model outputs):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zHdPZr60-0c_",
        "colab": {}
      },
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gVwoVij2lC7F"
      },
      "source": [
        "Let's have a look at the classification report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L8a9_8-ND3Is",
        "colab": {}
      },
      "source": [
        "print(classification_report(y_test, y_pred, target_names=class_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rFAekw3mmWUi"
      },
      "source": [
        "Looks like it is really hard to classify neutral (3 stars) reviews. And I can tell you from experience, looking at many reviews, those are hard to classify.\n",
        "\n",
        "We'll continue with the confusion matrix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6d1qxsc__DTh",
        "colab": {}
      },
      "source": [
        "def show_confusion_matrix(confusion_matrix):\n",
        "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
        "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "  plt.ylabel('True sentiment')\n",
        "  plt.xlabel('Predicted sentiment');\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "show_confusion_matrix(df_cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wx0U7oNsnZ3A"
      },
      "source": [
        "This confirms that our model is having difficulty classifying neutral reviews. It mistakes those for negative and positive at a roughly equal frequency.\n",
        "\n",
        "That's a good overview of the performance of our model. But let's have a look at an example from our test data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iANBiY3sLo-K",
        "colab": {}
      },
      "source": [
        "idx = 55\n",
        "\n",
        "review_text = y_review_texts[idx]\n",
        "true_sentiment = y_test[idx]\n",
        "pred_df = pd.DataFrame({\n",
        "  'class_names': class_names,\n",
        "  'values': y_pred_probs[idx]\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-8D0rb1yfnv4",
        "colab": {}
      },
      "source": [
        "print(\"\\n\".join(wrap(review_text)))\n",
        "print()\n",
        "print(f'True sentiment: {class_names[true_sentiment]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f7hj_IZFnn2X"
      },
      "source": [
        "Now we can look at the confidence of each sentiment of our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qj4d8lZyMkhf",
        "colab": {}
      },
      "source": [
        "sns.barplot(x='values', y='class_names', data=pred_df, orient='h')\n",
        "plt.ylabel('sentiment')\n",
        "plt.xlabel('probability')\n",
        "plt.xlim([0, 1]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7WL5pDmvFyaU"
      },
      "source": [
        "### Predicting on Raw Text\n",
        "\n",
        "Let's use our model to predict the sentiment of some raw text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DWPkea1zs0g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.sample()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QEPi7zQRsDhH",
        "colab": {}
      },
      "source": [
        "review_text = \"paskinta mainostusta mitä oon koskaan nähny\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GaN4RnqMnxYw"
      },
      "source": [
        "We have to use the tokenizer to encode the text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zA5Or4D2sLc9",
        "colab": {}
      },
      "source": [
        "encoded_review = tokenizer.encode_plus(\n",
        "  review_text,\n",
        "  max_length=MAX_LEN,\n",
        "  add_special_tokens=True,\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "et8xlDrKpH60"
      },
      "source": [
        "Let's get the predictions from our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Qr_t3rUksumr",
        "colab": {}
      },
      "source": [
        "input_ids = encoded_review['input_ids'].to(device)\n",
        "attention_mask = encoded_review['attention_mask'].to(device)\n",
        "\n",
        "output = model(input_ids, attention_mask)\n",
        "_, prediction = torch.max(output, dim=1)\n",
        "\n",
        "print(f'Review text: {review_text}')\n",
        "print(f'Sentiment  : {class_names[prediction]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PVhwzq7bpPRl"
      },
      "source": [
        "## Summary\n",
        "\n",
        "Nice job! You learned how to use BERT for sentiment analysis. You built a custom classifier using the Hugging Face library and trained it on our app reviews dataset!\n",
        "\n",
        "- [Read the tutorial](https://www.curiousily.com/posts/sentiment-analysis-with-bert-and-hugging-face-using-pytorch-and-python/)\n",
        "- [Run the notebook in your browser (Google Colab)](https://colab.research.google.com/drive/1PHv-IRLPCtv7oTcIGbsgZHqrB5LPvB7S)\n",
        "- [Read the `Getting Things Done with Pytorch` book](https://github.com/curiousily/Getting-Things-Done-with-Pytorch)\n",
        "\n",
        "You learned how to:\n",
        "\n",
        "- Intuitively understand what BERT is\n",
        "- Preprocess text data for BERT and build PyTorch Dataset (tokenization, attention masks, and padding)\n",
        "- Use Transfer Learning to build Sentiment Classifier using the Transformers library by Hugging Face\n",
        "- Evaluate the model on test data\n",
        "- Predict sentiment on raw text\n",
        "\n",
        "Next, we'll learn how to deploy our trained model behind a REST API and build a simple web app to access it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Wf39tauBa2V2"
      },
      "source": [
        "## References\n",
        "\n",
        "- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)\n",
        "- [L11 Language Models - Alec Radford (OpenAI)](https://www.youtube.com/watch?v=BnpB3GrpsfM)\n",
        "- [The Illustrated BERT, ELMo, and co.](https://jalammar.github.io/illustrated-bert/)\n",
        "- [BERT Fine-Tuning Tutorial with PyTorch](https://mccormickml.com/2019/07/22/BERT-fine-tuning/)\n",
        "- [How to Fine-Tune BERT for Text Classification?](https://arxiv.org/pdf/1905.05583.pdf)\n",
        "- [Huggingface Transformers](https://huggingface.co/transformers/)\n",
        "- [BERT Explained: State of the art language model for NLP](https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270)"
      ]
    }
  ]
}